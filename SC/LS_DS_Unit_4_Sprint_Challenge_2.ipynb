{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Chocolate Gummy Bears](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "4. [Keras MMP](#Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:**\n",
    "    A neuron is node in a layer of a neural network. The neurons calculate the weighted sum and use the activation function for determining what to pass on to next layer (depending on the function)\n",
    "- **Input Layer:**\n",
    "    This is the first layer of this Neural Net. It has one node/neuron for each feature\n",
    "- **Hidden Layer:**\n",
    "    These are all the layers in between the input and output layers. With each layer the input data gets a weighted sum calculated and is then acted upon by the activation function\n",
    "- **Output Layer:**\n",
    "    This is the final layer of the neural net. This will have as many nodes as outputs you want from the model. For a typical regression or binary classification this will typically be 1 node - just the single prediction. For multiclass-classification, such as in MNIST with img-number recognition, you would have an output node corresponding to all the possible outputs\n",
    "- **Activation:**\n",
    "    This is a function which determines what to pass on to the next layer. Most commonly, it is determining the strength, or weight, of the connection to the next layer.\n",
    "- **Backpropagation:**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chocolate Gummy Bears <a id=\"Q2\"></a>\n",
    "\n",
    "Right now, you're probably thinking, \"yuck, who the hell would eat that?\". Great question. Your candy company wants to know too. And you thought I was kidding about the [Chocolate Gummy Bears](https://nuts.com/chocolatessweets/gummies/gummy-bears/milk-gummy-bears.html?utm_source=google&utm_medium=cpc&adpos=1o1&gclid=Cj0KCQjwrfvsBRD7ARIsAKuDvMOZrysDku3jGuWaDqf9TrV3x5JLXt1eqnVhN0KM6fMcbA1nod3h8AwaAvWwEALw_wcB). \n",
    "\n",
    "Let's assume that a candy company has gone out and collected information on the types of Halloween candy kids ate. Our candy company wants to predict the eating behavior of witches, warlocks, and ghosts -- aka costumed kids. They shared a sample dataset with us. Each row represents a piece of candy that a costumed child was presented with during \"trick\" or \"treat\". We know if the candy was `chocolate` (or not chocolate) or `gummy` (or not gummy). Your goal is to predict if the costumed kid `ate` the piece of candy. \n",
    "\n",
    "If both chocolate and gummy equal one, you've got a chocolate gummy bear on your hands!?!?!\n",
    "![Chocolate Gummy Bear](https://ed910ae2d60f0d25bcb8-80550f96b5feb12604f4f720bfefb46d.ssl.cf1.rackcdn.com/3fb630c04435b7b5-2leZuM7_-zoom.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "candy = pd.read_csv('chocolate_gummy_bears.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>gummy</th>\n",
       "      <th>ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chocolate  gummy  ate\n",
       "0          0      1    1\n",
       "1          1      0    1\n",
       "2          0      1    1\n",
       "3          0      0    0\n",
       "4          1      1    0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(candy.shape)\n",
    "\n",
    "candy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "To make predictions on the `candy` dataframe. Build and train a Perceptron using numpy. Your target column is `ate` and your features: `chocolate` and `gummy`. Do not do any feature engineering. :P\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why you could not achieve a higher accuracy with a *simple perceptron*. It's possible to achieve ~95% accuracy on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Start your candy perceptron here\n",
    "\n",
    "X = candy[['chocolate', 'gummy']].values\n",
    "y = candy['ate'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 2), (10000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build Perceptron class\n",
    "class Perceptron(object):\n",
    "    def __init__(self, rate = 0.01, niter = 10):\n",
    "        self.rate = rate\n",
    "        self.niter = niter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "\n",
    "        # weights\n",
    "        self.weight = np.random.rand(1 + X.shape[1])\n",
    "\n",
    "        # Number of misclassifications\n",
    "        self.errors = []  # Number of misclassifications\n",
    "\n",
    "        for i in range(self.niter):\n",
    "            err = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                #print('weights:', self.weight)\n",
    "                delta_w = self.rate * (target - self.predict(xi))\n",
    "                #print('delta_w:', delta_w)\n",
    "                self.weight[1:] += delta_w * xi\n",
    "                self.weight[0] += delta_w\n",
    "                #print(self.weight[0])\n",
    "                err += int(delta_w != 0.0)\n",
    "                self.errors.append(err)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Perceptron at 0x7f4481b95510>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for some reason i cant figure out the model doesnt learn\n",
    "pn = Perceptron()\n",
    "pn.fit(X,y)\n",
    "preds = pn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Output\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "-------------------------\n",
      "Predicted Output\n",
      "[1 1 1 ... 1 1 1]\n",
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"True Output\")\n",
    "print(y)\n",
    "print('-'*25)\n",
    "print('Predicted Output')\n",
    "print(preds)\n",
    "print(\"Accuracy:\", accuracy_score(y, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason the accuracy is limited with Perceptron is that it only finds linear relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Using the sample candy dataset, implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. Your Multilayer Perceptron should be implemented in Numpy. \n",
    "Your network must have one hidden layer.\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why your MLP's performance is considerably better than your simple perceptron's on the candy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Multi-Layer Perceptron\n",
    "class NeuralNetwork: \n",
    "    def __init__(self, n_iter=10, lr=0.1):\n",
    "        # Set upArchietecture \n",
    "        self.inputs = 2\n",
    "        self.hiddenNodes = 6\n",
    "        self.outputNodes = 1\n",
    "        self.n_iter = n_iter\n",
    "        self.lr = lr\n",
    "        \n",
    "        #Initial weights\n",
    "        self.weights1 = np.random.rand(self.inputs, self.hiddenNodes) #2x3\n",
    "        self.weights2 = np.random.rand(self.hiddenNodes, self.outputNodes) #3x1\n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward.\n",
    "        \"\"\"\n",
    "        \n",
    "        #Weighted sume of inputs and hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        #Acivations of weighted sum\n",
    "        self.activated_hidden = expit(self.hidden_sum)\n",
    "        \n",
    "        # Weight sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        \n",
    "        #Final activation of output\n",
    "        self.activated_output = expit(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        \"\"\"\n",
    "        Backward propagate through the network\n",
    "        \"\"\"\n",
    "        self.o_error = self.lr * (y - o) #error in output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) # apply derivative of sigmoid to error\n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T) # z2 error: how much our hidden layer weights were off\n",
    "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.activated_hidden)\n",
    "        \n",
    "        self.weights1 += X.T.dot(self.z2_delta) #Adjust first set (input => hidden) weights\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta) #adjust second set (hidden => output) weights\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        for i in range(self.n_iter):\n",
    "            o = self.feed_forward(X)\n",
    "            self.backward(X, y, o)\n",
    "        \n",
    "    def accuracy(self, y):\n",
    "        pred = np.array([1 if p>=0.5 else 0 for p in self.activated_output])\n",
    "        y = y.reshape(1,-1)[0]\n",
    "        return accuracy_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 2), (10000, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()\n",
    "nn.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579606e-24]\n",
      " [1.11638588e-20]\n",
      " [1.94579606e-24]\n",
      " ...\n",
      " [1.94579606e-24]\n",
      " [1.94579606e-24]\n",
      " [1.11638588e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 2---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579606e-24]\n",
      " [1.11638588e-20]\n",
      " [1.94579606e-24]\n",
      " ...\n",
      " [1.94579606e-24]\n",
      " [1.94579606e-24]\n",
      " [1.11638588e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 3---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579606e-24]\n",
      " [1.11638588e-20]\n",
      " [1.94579606e-24]\n",
      " ...\n",
      " [1.94579606e-24]\n",
      " [1.94579606e-24]\n",
      " [1.11638588e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 4---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579606e-24]\n",
      " [1.11638588e-20]\n",
      " [1.94579606e-24]\n",
      " ...\n",
      " [1.94579606e-24]\n",
      " [1.94579606e-24]\n",
      " [1.11638588e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 5---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579606e-24]\n",
      " [1.11638588e-20]\n",
      " [1.94579606e-24]\n",
      " ...\n",
      " [1.94579606e-24]\n",
      " [1.94579606e-24]\n",
      " [1.11638588e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 50---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579606e-24]\n",
      " [1.11638589e-20]\n",
      " [1.94579606e-24]\n",
      " ...\n",
      " [1.94579606e-24]\n",
      " [1.94579606e-24]\n",
      " [1.11638589e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 100---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579608e-24]\n",
      " [1.11638589e-20]\n",
      " [1.94579608e-24]\n",
      " ...\n",
      " [1.94579608e-24]\n",
      " [1.94579608e-24]\n",
      " [1.11638589e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 150---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579609e-24]\n",
      " [1.11638590e-20]\n",
      " [1.94579609e-24]\n",
      " ...\n",
      " [1.94579609e-24]\n",
      " [1.94579609e-24]\n",
      " [1.11638590e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 200---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.9457961e-24]\n",
      " [1.1163859e-20]\n",
      " [1.9457961e-24]\n",
      " ...\n",
      " [1.9457961e-24]\n",
      " [1.9457961e-24]\n",
      " [1.1163859e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 250---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579611e-24]\n",
      " [1.11638591e-20]\n",
      " [1.94579611e-24]\n",
      " ...\n",
      " [1.94579611e-24]\n",
      " [1.94579611e-24]\n",
      " [1.11638591e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 300---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579612e-24]\n",
      " [1.11638592e-20]\n",
      " [1.94579612e-24]\n",
      " ...\n",
      " [1.94579612e-24]\n",
      " [1.94579612e-24]\n",
      " [1.11638592e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 350---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579613e-24]\n",
      " [1.11638592e-20]\n",
      " [1.94579613e-24]\n",
      " ...\n",
      " [1.94579613e-24]\n",
      " [1.94579613e-24]\n",
      " [1.11638592e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 400---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579614e-24]\n",
      " [1.11638593e-20]\n",
      " [1.94579614e-24]\n",
      " ...\n",
      " [1.94579614e-24]\n",
      " [1.94579614e-24]\n",
      " [1.11638593e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 450---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579615e-24]\n",
      " [1.11638593e-20]\n",
      " [1.94579615e-24]\n",
      " ...\n",
      " [1.94579615e-24]\n",
      " [1.94579615e-24]\n",
      " [1.11638593e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 500---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579616e-24]\n",
      " [1.11638594e-20]\n",
      " [1.94579616e-24]\n",
      " ...\n",
      " [1.94579616e-24]\n",
      " [1.94579616e-24]\n",
      " [1.11638594e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 550---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579617e-24]\n",
      " [1.11638594e-20]\n",
      " [1.94579617e-24]\n",
      " ...\n",
      " [1.94579617e-24]\n",
      " [1.94579617e-24]\n",
      " [1.11638594e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 600---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579618e-24]\n",
      " [1.11638595e-20]\n",
      " [1.94579618e-24]\n",
      " ...\n",
      " [1.94579618e-24]\n",
      " [1.94579618e-24]\n",
      " [1.11638595e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 650---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579619e-24]\n",
      " [1.11638595e-20]\n",
      " [1.94579619e-24]\n",
      " ...\n",
      " [1.94579619e-24]\n",
      " [1.94579619e-24]\n",
      " [1.11638595e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 700---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579620e-24]\n",
      " [1.11638596e-20]\n",
      " [1.94579620e-24]\n",
      " ...\n",
      " [1.94579620e-24]\n",
      " [1.94579620e-24]\n",
      " [1.11638596e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 750---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579621e-24]\n",
      " [1.11638597e-20]\n",
      " [1.94579621e-24]\n",
      " ...\n",
      " [1.94579621e-24]\n",
      " [1.94579621e-24]\n",
      " [1.11638597e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 800---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579622e-24]\n",
      " [1.11638597e-20]\n",
      " [1.94579622e-24]\n",
      " ...\n",
      " [1.94579622e-24]\n",
      " [1.94579622e-24]\n",
      " [1.11638597e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 850---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579623e-24]\n",
      " [1.11638598e-20]\n",
      " [1.94579623e-24]\n",
      " ...\n",
      " [1.94579623e-24]\n",
      " [1.94579623e-24]\n",
      " [1.11638598e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 900---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579624e-24]\n",
      " [1.11638598e-20]\n",
      " [1.94579624e-24]\n",
      " ...\n",
      " [1.94579624e-24]\n",
      " [1.94579624e-24]\n",
      " [1.11638598e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 950---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579625e-24]\n",
      " [1.11638599e-20]\n",
      " [1.94579625e-24]\n",
      " ...\n",
      " [1.94579625e-24]\n",
      " [1.94579625e-24]\n",
      " [1.11638599e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n",
      "+---------EPOCH 1000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.94579626e-24]\n",
      " [1.11638599e-20]\n",
      " [1.94579626e-24]\n",
      " ...\n",
      " [1.94579626e-24]\n",
      " [1.94579626e-24]\n",
      " [1.11638599e-20]]\n",
      "Loss: \n",
      " 0.49999999999999983\n",
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# dont know why this model doesnt train\n",
    "# same results everytime\n",
    "\n",
    "for i in range(1000):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 100 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print('Input: \\n', X)\n",
    "        print('Actual Output: \\n', y)\n",
    "        print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(X)))))\n",
    "        print(\"Accuracy:\", nn.accuracy(y))\n",
    "    nn.train(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Don't try candy gummy bears. They're disgusting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>178</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "102   63    0   1       140   195    0        1      179      0      0.0   \n",
       "101   59    1   3       178   270    0        0      145      0      4.2   \n",
       "242   64    1   0       145   212    0        0      132      0      2.0   \n",
       "257   50    1   0       144   200    0        0      126      1      0.9   \n",
       "225   70    1   0       145   174    0        1      125      1      2.6   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "102      2   2     2       1  \n",
       "101      0   0     3       1  \n",
       "242      1   2     1       0  \n",
       "257      1   0     3       0  \n",
       "225      0   0     3       0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x matrix and y vector\n",
    "X = df.drop(columns='target').values\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.544554\n",
       "0    0.455446\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Majority Class Baseline\n",
    "df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 54.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale X \n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create baseline model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(13, activation='relu', input_shape=(X.shape[1],)))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 272 samples, validate on 31 samples\n",
      "Epoch 1/10\n",
      "272/272 [==============================] - 1s 4ms/sample - loss: 0.7739 - accuracy: 0.4706 - val_loss: 0.5200 - val_accuracy: 0.7419\n",
      "Epoch 2/10\n",
      "272/272 [==============================] - 0s 158us/sample - loss: 0.7227 - accuracy: 0.5110 - val_loss: 0.5033 - val_accuracy: 0.8065\n",
      "Epoch 3/10\n",
      "272/272 [==============================] - 0s 153us/sample - loss: 0.6776 - accuracy: 0.5699 - val_loss: 0.4867 - val_accuracy: 0.8387\n",
      "Epoch 4/10\n",
      "272/272 [==============================] - 0s 150us/sample - loss: 0.6437 - accuracy: 0.6213 - val_loss: 0.4721 - val_accuracy: 0.8387\n",
      "Epoch 5/10\n",
      "272/272 [==============================] - 0s 150us/sample - loss: 0.6164 - accuracy: 0.6765 - val_loss: 0.4611 - val_accuracy: 0.8710\n",
      "Epoch 6/10\n",
      "272/272 [==============================] - 0s 159us/sample - loss: 0.5932 - accuracy: 0.7243 - val_loss: 0.4492 - val_accuracy: 0.8387\n",
      "Epoch 7/10\n",
      "272/272 [==============================] - 0s 163us/sample - loss: 0.5719 - accuracy: 0.7390 - val_loss: 0.4372 - val_accuracy: 0.8387\n",
      "Epoch 8/10\n",
      "272/272 [==============================] - 0s 155us/sample - loss: 0.5533 - accuracy: 0.7721 - val_loss: 0.4241 - val_accuracy: 0.8387\n",
      "Epoch 9/10\n",
      "272/272 [==============================] - 0s 167us/sample - loss: 0.5376 - accuracy: 0.7647 - val_loss: 0.4144 - val_accuracy: 0.8387\n",
      "Epoch 10/10\n",
      "272/272 [==============================] - 0s 159us/sample - loss: 0.5216 - accuracy: 0.7794 - val_loss: 0.4044 - val_accuracy: 0.9032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f589807b278>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model with random chosen values for baseline\n",
    "model.fit(X, y, batch_size=25, epochs=10, validation_split=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well the baseline model does significantly better than the majority class.\n",
    "\n",
    "Let's see about some Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 202 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.6672 - accuracy: 0.5248\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.6255 - accuracy: 0.6188\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 269us/sample - loss: 0.5941 - accuracy: 0.7277\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.5684 - accuracy: 0.7574\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.5448 - accuracy: 0.7772\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.5255 - accuracy: 0.7871\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 276us/sample - loss: 0.5066 - accuracy: 0.8020\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 295us/sample - loss: 0.4882 - accuracy: 0.8020\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.4695 - accuracy: 0.8168\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 312us/sample - loss: 0.4527 - accuracy: 0.8168\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.4789 - accuracy: 0.8218\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7484 - accuracy: 0.4554\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 302us/sample - loss: 0.6989 - accuracy: 0.5396\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 294us/sample - loss: 0.6583 - accuracy: 0.6436\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.6267 - accuracy: 0.6832\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 259us/sample - loss: 0.5982 - accuracy: 0.7178\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.5717 - accuracy: 0.7426\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.5480 - accuracy: 0.7525\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.5261 - accuracy: 0.7723\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.5059 - accuracy: 0.7822\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.4877 - accuracy: 0.7871\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 959us/sample - loss: 0.5134 - accuracy: 0.8020\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.8064 - accuracy: 0.4356\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.7397 - accuracy: 0.4653\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.6915 - accuracy: 0.4802\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.6564 - accuracy: 0.5594\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.6260 - accuracy: 0.6832\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.6016 - accuracy: 0.7376\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.5785 - accuracy: 0.7673\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 276us/sample - loss: 0.5545 - accuracy: 0.7723\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 291us/sample - loss: 0.5321 - accuracy: 0.7970\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.5102 - accuracy: 0.8069\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 998us/sample - loss: 0.4933 - accuracy: 0.7723\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6330 - accuracy: 0.6980\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 153us/sample - loss: 0.6195 - accuracy: 0.7228\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 147us/sample - loss: 0.6084 - accuracy: 0.7475\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.5976 - accuracy: 0.7624\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 158us/sample - loss: 0.5869 - accuracy: 0.7822\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 147us/sample - loss: 0.5756 - accuracy: 0.7871\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 152us/sample - loss: 0.5633 - accuracy: 0.7921\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 154us/sample - loss: 0.5515 - accuracy: 0.7970\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 158us/sample - loss: 0.5395 - accuracy: 0.8168\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 144us/sample - loss: 0.5274 - accuracy: 0.8168\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 936us/sample - loss: 0.4718 - accuracy: 0.7921\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 1.0150 - accuracy: 0.5297\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 146us/sample - loss: 0.9229 - accuracy: 0.5248\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 141us/sample - loss: 0.8490 - accuracy: 0.5297\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 142us/sample - loss: 0.7905 - accuracy: 0.5248\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 141us/sample - loss: 0.7360 - accuracy: 0.5446\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 139us/sample - loss: 0.6895 - accuracy: 0.5842\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 160us/sample - loss: 0.6495 - accuracy: 0.6040\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 159us/sample - loss: 0.6149 - accuracy: 0.6634\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 152us/sample - loss: 0.5874 - accuracy: 0.6931\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 148us/sample - loss: 0.5658 - accuracy: 0.7079\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 921us/sample - loss: 0.9311 - accuracy: 0.6634\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7211 - accuracy: 0.5594\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 143us/sample - loss: 0.6869 - accuracy: 0.5693\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.6590 - accuracy: 0.5990\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 150us/sample - loss: 0.6356 - accuracy: 0.6485\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 145us/sample - loss: 0.6156 - accuracy: 0.7129\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 153us/sample - loss: 0.5979 - accuracy: 0.7525\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 142us/sample - loss: 0.5819 - accuracy: 0.7525\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 143us/sample - loss: 0.5677 - accuracy: 0.7673\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 138us/sample - loss: 0.5546 - accuracy: 0.7772\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 147us/sample - loss: 0.5421 - accuracy: 0.7871\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 943us/sample - loss: 0.4438 - accuracy: 0.7525\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.8017 - accuracy: 0.4059\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 99us/sample - loss: 0.7673 - accuracy: 0.4307\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 101us/sample - loss: 0.7394 - accuracy: 0.4703\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 101us/sample - loss: 0.7140 - accuracy: 0.5248\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 95us/sample - loss: 0.6934 - accuracy: 0.5644\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 95us/sample - loss: 0.6745 - accuracy: 0.6287\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 94us/sample - loss: 0.6580 - accuracy: 0.6584\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 99us/sample - loss: 0.6424 - accuracy: 0.6931\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 98us/sample - loss: 0.6304 - accuracy: 0.7178\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 98us/sample - loss: 0.6184 - accuracy: 0.7228\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 852us/sample - loss: 0.6407 - accuracy: 0.7030\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6682 - accuracy: 0.6287\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 96us/sample - loss: 0.6477 - accuracy: 0.6436\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 91us/sample - loss: 0.6296 - accuracy: 0.6634\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 90us/sample - loss: 0.6136 - accuracy: 0.6931\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 98us/sample - loss: 0.5986 - accuracy: 0.7079\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 88us/sample - loss: 0.5842 - accuracy: 0.7178\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 86us/sample - loss: 0.5714 - accuracy: 0.7129\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 91us/sample - loss: 0.5578 - accuracy: 0.7228\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 98us/sample - loss: 0.5455 - accuracy: 0.7277\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 94us/sample - loss: 0.5328 - accuracy: 0.7376\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 896us/sample - loss: 0.4842 - accuracy: 0.7921\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.6969 - accuracy: 0.5099\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 95us/sample - loss: 0.6713 - accuracy: 0.5347\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 94us/sample - loss: 0.6464 - accuracy: 0.5545\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 93us/sample - loss: 0.6239 - accuracy: 0.5941\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 93us/sample - loss: 0.6049 - accuracy: 0.6436\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 100us/sample - loss: 0.5862 - accuracy: 0.6782\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 97us/sample - loss: 0.5696 - accuracy: 0.7228\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 92us/sample - loss: 0.5553 - accuracy: 0.7624\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 93us/sample - loss: 0.5408 - accuracy: 0.7921\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 95us/sample - loss: 0.5278 - accuracy: 0.7970\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 925us/sample - loss: 0.5623 - accuracy: 0.6634\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7938 - accuracy: 0.5347\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 81us/sample - loss: 0.7681 - accuracy: 0.5347\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 84us/sample - loss: 0.7471 - accuracy: 0.5446\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 81us/sample - loss: 0.7297 - accuracy: 0.5545\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 82us/sample - loss: 0.7106 - accuracy: 0.5594\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 82us/sample - loss: 0.6926 - accuracy: 0.5693\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 84us/sample - loss: 0.6778 - accuracy: 0.5743\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 80us/sample - loss: 0.6646 - accuracy: 0.5842\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 90us/sample - loss: 0.6531 - accuracy: 0.5891\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 84us/sample - loss: 0.6416 - accuracy: 0.5990\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 894us/sample - loss: 0.5792 - accuracy: 0.4950\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.7187 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 90us/sample - loss: 0.7018 - accuracy: 0.5495\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 83us/sample - loss: 0.6891 - accuracy: 0.5693\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 87us/sample - loss: 0.6781 - accuracy: 0.5990\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 83us/sample - loss: 0.6677 - accuracy: 0.6089\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 83us/sample - loss: 0.6579 - accuracy: 0.6238\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 84us/sample - loss: 0.6492 - accuracy: 0.6436\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 81us/sample - loss: 0.6411 - accuracy: 0.6535\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 83us/sample - loss: 0.6329 - accuracy: 0.6634\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 83us/sample - loss: 0.6251 - accuracy: 0.6634\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 889us/sample - loss: 0.6103 - accuracy: 0.6535\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7838 - accuracy: 0.4356\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 89us/sample - loss: 0.7648 - accuracy: 0.4505\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 85us/sample - loss: 0.7505 - accuracy: 0.4703\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 82us/sample - loss: 0.7380 - accuracy: 0.4703\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 85us/sample - loss: 0.7253 - accuracy: 0.4851\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 83us/sample - loss: 0.7132 - accuracy: 0.5149\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 82us/sample - loss: 0.7028 - accuracy: 0.5446\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 90us/sample - loss: 0.6936 - accuracy: 0.5644\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 83us/sample - loss: 0.6851 - accuracy: 0.5792\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 89us/sample - loss: 0.6772 - accuracy: 0.5842\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 898us/sample - loss: 0.6522 - accuracy: 0.5149\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.9695 - accuracy: 0.4505\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 67us/sample - loss: 0.9308 - accuracy: 0.4505\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 71us/sample - loss: 0.8971 - accuracy: 0.4505\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 67us/sample - loss: 0.8709 - accuracy: 0.4505\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 65us/sample - loss: 0.8453 - accuracy: 0.4505\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 67us/sample - loss: 0.8220 - accuracy: 0.4505\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 70us/sample - loss: 0.8002 - accuracy: 0.4505\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 68us/sample - loss: 0.7814 - accuracy: 0.4554\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 77us/sample - loss: 0.7659 - accuracy: 0.4554\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 68us/sample - loss: 0.7509 - accuracy: 0.4554\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 889us/sample - loss: 0.8326 - accuracy: 0.4851\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7250 - accuracy: 0.3812\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 81us/sample - loss: 0.7179 - accuracy: 0.4010\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 74us/sample - loss: 0.7123 - accuracy: 0.4257\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 72us/sample - loss: 0.7075 - accuracy: 0.4406\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 69us/sample - loss: 0.7027 - accuracy: 0.4604\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 72us/sample - loss: 0.6978 - accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 69us/sample - loss: 0.6931 - accuracy: 0.5198\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 69us/sample - loss: 0.6888 - accuracy: 0.5248\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 69us/sample - loss: 0.6852 - accuracy: 0.5545\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 73us/sample - loss: 0.6809 - accuracy: 0.5545\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.6907 - accuracy: 0.5743\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7558 - accuracy: 0.5693\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 71us/sample - loss: 0.7302 - accuracy: 0.5990\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 68us/sample - loss: 0.7094 - accuracy: 0.6188\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 71us/sample - loss: 0.6899 - accuracy: 0.6337\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 75us/sample - loss: 0.6747 - accuracy: 0.6485\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 73us/sample - loss: 0.6576 - accuracy: 0.6634\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 73us/sample - loss: 0.6420 - accuracy: 0.6634\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 78us/sample - loss: 0.6288 - accuracy: 0.6881\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 70us/sample - loss: 0.6164 - accuracy: 0.6931\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 70us/sample - loss: 0.6036 - accuracy: 0.7079\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 867us/sample - loss: 0.4479 - accuracy: 0.6832\n",
      "Train on 303 samples\n",
      "Epoch 1/10\n",
      "303/303 [==============================] - 0s 2ms/sample - loss: 0.7053 - accuracy: 0.4818\n",
      "Epoch 2/10\n",
      "303/303 [==============================] - 0s 263us/sample - loss: 0.6636 - accuracy: 0.6172\n",
      "Epoch 3/10\n",
      "303/303 [==============================] - 0s 262us/sample - loss: 0.6282 - accuracy: 0.7030\n",
      "Epoch 4/10\n",
      "303/303 [==============================] - 0s 260us/sample - loss: 0.5930 - accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "303/303 [==============================] - 0s 252us/sample - loss: 0.5561 - accuracy: 0.7690\n",
      "Epoch 6/10\n",
      "303/303 [==============================] - 0s 260us/sample - loss: 0.5182 - accuracy: 0.7789\n",
      "Epoch 7/10\n",
      "303/303 [==============================] - 0s 299us/sample - loss: 0.4819 - accuracy: 0.7954\n",
      "Epoch 8/10\n",
      "303/303 [==============================] - 0s 275us/sample - loss: 0.4501 - accuracy: 0.7954\n",
      "Epoch 9/10\n",
      "303/303 [==============================] - 0s 255us/sample - loss: 0.4250 - accuracy: 0.8086\n",
      "Epoch 10/10\n",
      "303/303 [==============================] - 0s 259us/sample - loss: 0.4056 - accuracy: 0.8218\n"
     ]
    }
   ],
   "source": [
    "# create model f(x) for keras sklearn wrapper\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(13, activation='relu', input_shape=(X.shape[1],)))\n",
    "    model.add(Dense(6, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=True)\n",
    "\n",
    "# exploring batch size\n",
    "param_grid = {\n",
    "    'batch_size': [10,20,30,40,50],\n",
    "    'epochs': [10]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_results = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'batch_size': 10, 'epochs': 10}\n",
      "Best Score with these Params: 0.7986798683802286\n"
     ]
    }
   ],
   "source": [
    "# Did only slightly better, but decided 10 was best batch size\n",
    "print(\"Best Params:\", grid_results.best_params_)\n",
    "print(\"Best Score with these Params:\", grid_results.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6215 - accuracy: 0.6188\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.5961 - accuracy: 0.6733\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.5729 - accuracy: 0.7475\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.5494 - accuracy: 0.7673\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 286us/sample - loss: 0.5292 - accuracy: 0.7921\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.5087 - accuracy: 0.8267\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.4903 - accuracy: 0.8267\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.4737 - accuracy: 0.8366\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.4579 - accuracy: 0.8267\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.4443 - accuracy: 0.8317\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.3728 - accuracy: 0.8317\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.8471 - accuracy: 0.5248\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.7731 - accuracy: 0.5248\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.7182 - accuracy: 0.5347\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.6771 - accuracy: 0.5594\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.6438 - accuracy: 0.5792\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.6184 - accuracy: 0.6287\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 274us/sample - loss: 0.5975 - accuracy: 0.6535\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.5802 - accuracy: 0.6733\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.5652 - accuracy: 0.6931\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.5530 - accuracy: 0.7030\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.6206 - accuracy: 0.7525\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.6937 - accuracy: 0.5495\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.6438 - accuracy: 0.5941\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 290us/sample - loss: 0.6011 - accuracy: 0.6535\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.5650 - accuracy: 0.6881\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 269us/sample - loss: 0.5349 - accuracy: 0.7228\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 321us/sample - loss: 0.5092 - accuracy: 0.7475\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.4849 - accuracy: 0.7723\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 298us/sample - loss: 0.4640 - accuracy: 0.7772\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 293us/sample - loss: 0.4441 - accuracy: 0.7871\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 300us/sample - loss: 0.4268 - accuracy: 0.7970\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.3899 - accuracy: 0.7525\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.9759 - accuracy: 0.4505\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 282us/sample - loss: 0.8561 - accuracy: 0.4604\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 289us/sample - loss: 0.7780 - accuracy: 0.4653\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.7265 - accuracy: 0.5050\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 297us/sample - loss: 0.6908 - accuracy: 0.5693\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 311us/sample - loss: 0.6676 - accuracy: 0.5990\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 307us/sample - loss: 0.6482 - accuracy: 0.6337\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 275us/sample - loss: 0.6325 - accuracy: 0.6683\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.6181 - accuracy: 0.6881\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 275us/sample - loss: 0.6047 - accuracy: 0.6980\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.5913 - accuracy: 0.7178\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.5798 - accuracy: 0.7178\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.5687 - accuracy: 0.7376\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 258us/sample - loss: 0.5600 - accuracy: 0.7574\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.5504 - accuracy: 0.7525\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 274us/sample - loss: 0.5417 - accuracy: 0.7673\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.5338 - accuracy: 0.7871\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.5264 - accuracy: 0.7921\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 291us/sample - loss: 0.5193 - accuracy: 0.7970\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 323us/sample - loss: 0.5135 - accuracy: 0.8119\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.6245 - accuracy: 0.7921\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6085 - accuracy: 0.6832\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 258us/sample - loss: 0.5550 - accuracy: 0.7079\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 254us/sample - loss: 0.5178 - accuracy: 0.7525\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.4906 - accuracy: 0.7921\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 258us/sample - loss: 0.4694 - accuracy: 0.7970\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.4490 - accuracy: 0.8119\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.4341 - accuracy: 0.8218\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 259us/sample - loss: 0.4197 - accuracy: 0.8267\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.4075 - accuracy: 0.8267\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.3968 - accuracy: 0.8267\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 251us/sample - loss: 0.3873 - accuracy: 0.8267\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.3790 - accuracy: 0.8317\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 249us/sample - loss: 0.3730 - accuracy: 0.8317\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 250us/sample - loss: 0.3669 - accuracy: 0.8366\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.3606 - accuracy: 0.8317\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.3562 - accuracy: 0.8366\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.3499 - accuracy: 0.8515\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 249us/sample - loss: 0.3456 - accuracy: 0.8515\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.3409 - accuracy: 0.8465\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 269us/sample - loss: 0.3371 - accuracy: 0.8465\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 995us/sample - loss: 0.3455 - accuracy: 0.8317\n",
      "Train on 202 samples\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7183 - accuracy: 0.5198\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.6450 - accuracy: 0.6188\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 259us/sample - loss: 0.5961 - accuracy: 0.7129\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.5568 - accuracy: 0.7475\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 249us/sample - loss: 0.5271 - accuracy: 0.7871\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.5016 - accuracy: 0.7970\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 249us/sample - loss: 0.4809 - accuracy: 0.8020\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 269us/sample - loss: 0.4623 - accuracy: 0.8119\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.4461 - accuracy: 0.8218\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 278us/sample - loss: 0.4314 - accuracy: 0.8168\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.4168 - accuracy: 0.8119\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 276us/sample - loss: 0.4052 - accuracy: 0.8119\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.3932 - accuracy: 0.8218\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.3822 - accuracy: 0.8267\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.3725 - accuracy: 0.8564\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.3634 - accuracy: 0.8564\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 293us/sample - loss: 0.3556 - accuracy: 0.8564\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.3475 - accuracy: 0.8614\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.3427 - accuracy: 0.8614\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.3356 - accuracy: 0.8663\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 971us/sample - loss: 0.3182 - accuracy: 0.7921\n",
      "Train on 202 samples\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.7965 - accuracy: 0.3960\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.7531 - accuracy: 0.4257\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.7221 - accuracy: 0.4703\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 275us/sample - loss: 0.6971 - accuracy: 0.5248\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.6760 - accuracy: 0.5446\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.6565 - accuracy: 0.6040\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 247us/sample - loss: 0.6340 - accuracy: 0.6584\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 248us/sample - loss: 0.6085 - accuracy: 0.7228\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.5816 - accuracy: 0.7376\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 314us/sample - loss: 0.5497 - accuracy: 0.7525\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 284us/sample - loss: 0.5193 - accuracy: 0.7772\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.4880 - accuracy: 0.8069\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 275us/sample - loss: 0.4589 - accuracy: 0.8218\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 269us/sample - loss: 0.4338 - accuracy: 0.8218\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.4134 - accuracy: 0.8218\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.3941 - accuracy: 0.8168\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 287us/sample - loss: 0.3797 - accuracy: 0.8317\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.3669 - accuracy: 0.8317\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 246us/sample - loss: 0.3557 - accuracy: 0.8465\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 290us/sample - loss: 0.3468 - accuracy: 0.8614\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.3388 - accuracy: 0.8614\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 0s 365us/sample - loss: 0.3326 - accuracy: 0.8663\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.3269 - accuracy: 0.8614\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.3210 - accuracy: 0.8663\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 254us/sample - loss: 0.3168 - accuracy: 0.8663\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.3128 - accuracy: 0.8713\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.3077 - accuracy: 0.8812\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.3048 - accuracy: 0.8812\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.2998 - accuracy: 0.8762\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.2957 - accuracy: 0.8861\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.2931 - accuracy: 0.8861\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.2886 - accuracy: 0.8812\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.2866 - accuracy: 0.8812\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.2830 - accuracy: 0.8861\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 250us/sample - loss: 0.2800 - accuracy: 0.8812\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.2774 - accuracy: 0.8861\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 248us/sample - loss: 0.2740 - accuracy: 0.8911\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 246us/sample - loss: 0.2715 - accuracy: 0.8960\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 251us/sample - loss: 0.2685 - accuracy: 0.8960\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.2664 - accuracy: 0.9010\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.2633 - accuracy: 0.9010\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.2597 - accuracy: 0.9059\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 259us/sample - loss: 0.2578 - accuracy: 0.9059\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 0s 258us/sample - loss: 0.2560 - accuracy: 0.9059\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.2527 - accuracy: 0.9109\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.2514 - accuracy: 0.9109\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.2491 - accuracy: 0.9109\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.2466 - accuracy: 0.9109\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.2454 - accuracy: 0.9059\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.2431 - accuracy: 0.9059\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.4630 - accuracy: 0.8713\n",
      "Train on 202 samples\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7054 - accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.6699 - accuracy: 0.5297\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.6424 - accuracy: 0.5941\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.6166 - accuracy: 0.6386\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 287us/sample - loss: 0.5942 - accuracy: 0.6733\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.5712 - accuracy: 0.7030\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.5514 - accuracy: 0.7228\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.5329 - accuracy: 0.7426\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.5137 - accuracy: 0.7426\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.4950 - accuracy: 0.7574\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.4763 - accuracy: 0.7574\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.4589 - accuracy: 0.7624\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 247us/sample - loss: 0.4440 - accuracy: 0.7772\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.4304 - accuracy: 0.7871\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 278us/sample - loss: 0.4177 - accuracy: 0.7921\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.4078 - accuracy: 0.7970\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 247us/sample - loss: 0.3970 - accuracy: 0.8119\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 246us/sample - loss: 0.3874 - accuracy: 0.8267\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.3782 - accuracy: 0.8317\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.3695 - accuracy: 0.8366\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.3611 - accuracy: 0.8366\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.3545 - accuracy: 0.8465\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.3469 - accuracy: 0.8465\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.3410 - accuracy: 0.8515\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.3347 - accuracy: 0.8515\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 283us/sample - loss: 0.3300 - accuracy: 0.8614\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 269us/sample - loss: 0.3248 - accuracy: 0.8762\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 287us/sample - loss: 0.3206 - accuracy: 0.8762\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 319us/sample - loss: 0.3169 - accuracy: 0.8713\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 269us/sample - loss: 0.3132 - accuracy: 0.8762\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 258us/sample - loss: 0.3092 - accuracy: 0.8812\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.3052 - accuracy: 0.8812\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 274us/sample - loss: 0.3018 - accuracy: 0.8812\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 282us/sample - loss: 0.2974 - accuracy: 0.8812\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 297us/sample - loss: 0.2953 - accuracy: 0.8812\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.2918 - accuracy: 0.8861\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.2889 - accuracy: 0.8911\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 282us/sample - loss: 0.2857 - accuracy: 0.8911\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 251us/sample - loss: 0.2826 - accuracy: 0.8960\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.2805 - accuracy: 0.8960\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 299us/sample - loss: 0.2781 - accuracy: 0.8812\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 343us/sample - loss: 0.2750 - accuracy: 0.8812\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.2732 - accuracy: 0.8911\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 0s 296us/sample - loss: 0.2698 - accuracy: 0.8911\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.2676 - accuracy: 0.8911\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.2647 - accuracy: 0.8911\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.2627 - accuracy: 0.8911\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.2607 - accuracy: 0.8911\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.2574 - accuracy: 0.8911\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.2557 - accuracy: 0.8911\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 999us/sample - loss: 0.3061 - accuracy: 0.7921\n",
      "Train on 202 samples\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 1s 4ms/sample - loss: 0.7514 - accuracy: 0.4208\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 275us/sample - loss: 0.7033 - accuracy: 0.5495\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.6693 - accuracy: 0.6535\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.6424 - accuracy: 0.7030\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.6191 - accuracy: 0.6980\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.5924 - accuracy: 0.7327\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.5681 - accuracy: 0.7426\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.5444 - accuracy: 0.7673\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.5207 - accuracy: 0.7822\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.4986 - accuracy: 0.7921\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 322us/sample - loss: 0.4771 - accuracy: 0.7921\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.4571 - accuracy: 0.8020\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.4413 - accuracy: 0.8020\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.4255 - accuracy: 0.8119\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 269us/sample - loss: 0.4112 - accuracy: 0.8119\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.3997 - accuracy: 0.8168\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 283us/sample - loss: 0.3905 - accuracy: 0.8218\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 308us/sample - loss: 0.3801 - accuracy: 0.8218\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 288us/sample - loss: 0.3722 - accuracy: 0.8218\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.3647 - accuracy: 0.8218\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.3571 - accuracy: 0.8317\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 0s 282us/sample - loss: 0.3512 - accuracy: 0.8366\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.3448 - accuracy: 0.8416\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.3412 - accuracy: 0.8465\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.3364 - accuracy: 0.8465\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.3331 - accuracy: 0.8465\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 259us/sample - loss: 0.3289 - accuracy: 0.8515\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.3256 - accuracy: 0.8465\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 269us/sample - loss: 0.3215 - accuracy: 0.8465\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.3181 - accuracy: 0.8515\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 274us/sample - loss: 0.3147 - accuracy: 0.8515\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 275us/sample - loss: 0.3110 - accuracy: 0.8564\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.3079 - accuracy: 0.8614\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.3058 - accuracy: 0.8663\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 278us/sample - loss: 0.3032 - accuracy: 0.8713\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 278us/sample - loss: 0.2993 - accuracy: 0.8614\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 288us/sample - loss: 0.2979 - accuracy: 0.8564\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.2954 - accuracy: 0.8663\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 309us/sample - loss: 0.2921 - accuracy: 0.8663\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.2897 - accuracy: 0.8663\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 275us/sample - loss: 0.2874 - accuracy: 0.8663\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.2853 - accuracy: 0.8663\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 259us/sample - loss: 0.2832 - accuracy: 0.8663\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.2809 - accuracy: 0.8663\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.2781 - accuracy: 0.8663\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.2759 - accuracy: 0.8713\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.2746 - accuracy: 0.8713\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.2723 - accuracy: 0.8713\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 254us/sample - loss: 0.2703 - accuracy: 0.8713\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.2672 - accuracy: 0.8713\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.2768 - accuracy: 0.7921\n",
      "Train on 202 samples\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7395 - accuracy: 0.3317\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.7163 - accuracy: 0.4010\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.7003 - accuracy: 0.4653\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 0s 278us/sample - loss: 0.6864 - accuracy: 0.5545\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 0s 288us/sample - loss: 0.6746 - accuracy: 0.5941\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.6636 - accuracy: 0.6337\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.6526 - accuracy: 0.6733\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.6396 - accuracy: 0.6980\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.6262 - accuracy: 0.7327\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.6105 - accuracy: 0.7525\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 0s 285us/sample - loss: 0.5923 - accuracy: 0.7525\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.5734 - accuracy: 0.7574\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 0s 379us/sample - loss: 0.5543 - accuracy: 0.7772\n",
      "Epoch 14/100\n",
      "202/202 [==============================] - 0s 307us/sample - loss: 0.5332 - accuracy: 0.7822\n",
      "Epoch 15/100\n",
      "202/202 [==============================] - 0s 284us/sample - loss: 0.5125 - accuracy: 0.7921\n",
      "Epoch 16/100\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.4931 - accuracy: 0.7921\n",
      "Epoch 17/100\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.4708 - accuracy: 0.8069\n",
      "Epoch 18/100\n",
      "202/202 [==============================] - 0s 279us/sample - loss: 0.4513 - accuracy: 0.8119\n",
      "Epoch 19/100\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.4343 - accuracy: 0.8168\n",
      "Epoch 20/100\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.4167 - accuracy: 0.8564\n",
      "Epoch 21/100\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.4013 - accuracy: 0.8713\n",
      "Epoch 22/100\n",
      "202/202 [==============================] - 0s 275us/sample - loss: 0.3888 - accuracy: 0.8713\n",
      "Epoch 23/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.3767 - accuracy: 0.8663\n",
      "Epoch 24/100\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.3663 - accuracy: 0.8663\n",
      "Epoch 25/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.3577 - accuracy: 0.8663\n",
      "Epoch 26/100\n",
      "202/202 [==============================] - 0s 269us/sample - loss: 0.3495 - accuracy: 0.8663\n",
      "Epoch 27/100\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.3433 - accuracy: 0.8614\n",
      "Epoch 28/100\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.3399 - accuracy: 0.8614\n",
      "Epoch 29/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.3329 - accuracy: 0.8564\n",
      "Epoch 30/100\n",
      "202/202 [==============================] - 0s 274us/sample - loss: 0.3278 - accuracy: 0.8515\n",
      "Epoch 31/100\n",
      "202/202 [==============================] - 0s 290us/sample - loss: 0.3229 - accuracy: 0.8614\n",
      "Epoch 32/100\n",
      "202/202 [==============================] - 0s 295us/sample - loss: 0.3212 - accuracy: 0.8713\n",
      "Epoch 33/100\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.3167 - accuracy: 0.8762\n",
      "Epoch 34/100\n",
      "202/202 [==============================] - 0s 259us/sample - loss: 0.3115 - accuracy: 0.8713\n",
      "Epoch 35/100\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.3078 - accuracy: 0.8713\n",
      "Epoch 36/100\n",
      "202/202 [==============================] - 0s 278us/sample - loss: 0.3033 - accuracy: 0.8713\n",
      "Epoch 37/100\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.3011 - accuracy: 0.8614\n",
      "Epoch 38/100\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.2982 - accuracy: 0.8614\n",
      "Epoch 39/100\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.2947 - accuracy: 0.8663\n",
      "Epoch 40/100\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.2922 - accuracy: 0.8663\n",
      "Epoch 41/100\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.2885 - accuracy: 0.8663\n",
      "Epoch 42/100\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.2871 - accuracy: 0.8713\n",
      "Epoch 43/100\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.2830 - accuracy: 0.8713\n",
      "Epoch 44/100\n",
      "202/202 [==============================] - 0s 288us/sample - loss: 0.2799 - accuracy: 0.8762\n",
      "Epoch 45/100\n",
      "202/202 [==============================] - 0s 275us/sample - loss: 0.2780 - accuracy: 0.8762\n",
      "Epoch 46/100\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.2756 - accuracy: 0.8762\n",
      "Epoch 47/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.2720 - accuracy: 0.8812\n",
      "Epoch 48/100\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.2701 - accuracy: 0.8812\n",
      "Epoch 49/100\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.2677 - accuracy: 0.8911\n",
      "Epoch 50/100\n",
      "202/202 [==============================] - 0s 258us/sample - loss: 0.2655 - accuracy: 0.8861\n",
      "Epoch 51/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.2618 - accuracy: 0.8911\n",
      "Epoch 52/100\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.2603 - accuracy: 0.8960\n",
      "Epoch 53/100\n",
      "202/202 [==============================] - 0s 291us/sample - loss: 0.2576 - accuracy: 0.8960\n",
      "Epoch 54/100\n",
      "202/202 [==============================] - 0s 286us/sample - loss: 0.2565 - accuracy: 0.8911\n",
      "Epoch 55/100\n",
      "202/202 [==============================] - 0s 296us/sample - loss: 0.2529 - accuracy: 0.9010\n",
      "Epoch 56/100\n",
      "202/202 [==============================] - 0s 287us/sample - loss: 0.2513 - accuracy: 0.8911\n",
      "Epoch 57/100\n",
      "202/202 [==============================] - 0s 274us/sample - loss: 0.2491 - accuracy: 0.8960\n",
      "Epoch 58/100\n",
      "202/202 [==============================] - 0s 289us/sample - loss: 0.2481 - accuracy: 0.8911\n",
      "Epoch 59/100\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.2455 - accuracy: 0.9010\n",
      "Epoch 60/100\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.2440 - accuracy: 0.9010\n",
      "Epoch 61/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.2416 - accuracy: 0.9010\n",
      "Epoch 62/100\n",
      "202/202 [==============================] - 0s 259us/sample - loss: 0.2395 - accuracy: 0.8960\n",
      "Epoch 63/100\n",
      "202/202 [==============================] - 0s 298us/sample - loss: 0.2370 - accuracy: 0.9010\n",
      "Epoch 64/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.2352 - accuracy: 0.9010\n",
      "Epoch 65/100\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.2353 - accuracy: 0.9059\n",
      "Epoch 66/100\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.2317 - accuracy: 0.9109\n",
      "Epoch 67/100\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.2309 - accuracy: 0.9109\n",
      "Epoch 68/100\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.2286 - accuracy: 0.9158\n",
      "Epoch 69/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.2266 - accuracy: 0.9158\n",
      "Epoch 70/100\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.2256 - accuracy: 0.9208\n",
      "Epoch 71/100\n",
      "202/202 [==============================] - 0s 269us/sample - loss: 0.2235 - accuracy: 0.9208\n",
      "Epoch 72/100\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.2226 - accuracy: 0.9158\n",
      "Epoch 73/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.2202 - accuracy: 0.9208\n",
      "Epoch 74/100\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.2191 - accuracy: 0.9158\n",
      "Epoch 75/100\n",
      "202/202 [==============================] - 0s 282us/sample - loss: 0.2174 - accuracy: 0.9208\n",
      "Epoch 76/100\n",
      "202/202 [==============================] - 0s 274us/sample - loss: 0.2154 - accuracy: 0.9208\n",
      "Epoch 77/100\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.2141 - accuracy: 0.9208\n",
      "Epoch 78/100\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.2126 - accuracy: 0.9208\n",
      "Epoch 79/100\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.2109 - accuracy: 0.9257\n",
      "Epoch 80/100\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.2101 - accuracy: 0.9257\n",
      "Epoch 81/100\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.2074 - accuracy: 0.9257\n",
      "Epoch 82/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.2057 - accuracy: 0.9257\n",
      "Epoch 83/100\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.2041 - accuracy: 0.9208\n",
      "Epoch 84/100\n",
      "202/202 [==============================] - 0s 318us/sample - loss: 0.2032 - accuracy: 0.9208\n",
      "Epoch 85/100\n",
      "202/202 [==============================] - 0s 337us/sample - loss: 0.2015 - accuracy: 0.9257\n",
      "Epoch 86/100\n",
      "202/202 [==============================] - 0s 294us/sample - loss: 0.2010 - accuracy: 0.9257\n",
      "Epoch 87/100\n",
      "202/202 [==============================] - 0s 276us/sample - loss: 0.1993 - accuracy: 0.9257\n",
      "Epoch 88/100\n",
      "202/202 [==============================] - 0s 290us/sample - loss: 0.1977 - accuracy: 0.9208\n",
      "Epoch 89/100\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.1957 - accuracy: 0.9208\n",
      "Epoch 90/100\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.1948 - accuracy: 0.9257\n",
      "Epoch 91/100\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.1931 - accuracy: 0.9208\n",
      "Epoch 92/100\n",
      "202/202 [==============================] - 0s 278us/sample - loss: 0.1927 - accuracy: 0.9406\n",
      "Epoch 93/100\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.1910 - accuracy: 0.9356\n",
      "Epoch 94/100\n",
      "202/202 [==============================] - 0s 276us/sample - loss: 0.1894 - accuracy: 0.9307\n",
      "Epoch 95/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.1894 - accuracy: 0.9307\n",
      "Epoch 96/100\n",
      "202/202 [==============================] - 0s 293us/sample - loss: 0.1869 - accuracy: 0.9307\n",
      "Epoch 97/100\n",
      "202/202 [==============================] - 0s 304us/sample - loss: 0.1861 - accuracy: 0.9307\n",
      "Epoch 98/100\n",
      "202/202 [==============================] - 0s 280us/sample - loss: 0.1835 - accuracy: 0.9307\n",
      "Epoch 99/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.1831 - accuracy: 0.9257\n",
      "Epoch 100/100\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.1815 - accuracy: 0.9208\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.2540 - accuracy: 0.8416\n",
      "Train on 202 samples\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.6675 - accuracy: 0.6040\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.6066 - accuracy: 0.6881\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.5574 - accuracy: 0.7376\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.5149 - accuracy: 0.7921\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 0s 248us/sample - loss: 0.4810 - accuracy: 0.7970\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 0s 250us/sample - loss: 0.4511 - accuracy: 0.8119\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.4296 - accuracy: 0.8366\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.4132 - accuracy: 0.8465\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.3986 - accuracy: 0.8515\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.3882 - accuracy: 0.8515\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 0s 254us/sample - loss: 0.3779 - accuracy: 0.8614\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.3700 - accuracy: 0.8564\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.3626 - accuracy: 0.8564\n",
      "Epoch 14/100\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.3567 - accuracy: 0.8564\n",
      "Epoch 15/100\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.3517 - accuracy: 0.8614\n",
      "Epoch 16/100\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.3459 - accuracy: 0.8663\n",
      "Epoch 17/100\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.3413 - accuracy: 0.8663\n",
      "Epoch 18/100\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.3355 - accuracy: 0.8663\n",
      "Epoch 19/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.3340 - accuracy: 0.8713\n",
      "Epoch 20/100\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.3286 - accuracy: 0.8762\n",
      "Epoch 21/100\n",
      "202/202 [==============================] - 0s 276us/sample - loss: 0.3252 - accuracy: 0.8762\n",
      "Epoch 22/100\n",
      "202/202 [==============================] - 0s 285us/sample - loss: 0.3211 - accuracy: 0.8713\n",
      "Epoch 23/100\n",
      "202/202 [==============================] - 0s 286us/sample - loss: 0.3175 - accuracy: 0.8713\n",
      "Epoch 24/100\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.3140 - accuracy: 0.8812\n",
      "Epoch 25/100\n",
      "202/202 [==============================] - 0s 284us/sample - loss: 0.3114 - accuracy: 0.8713\n",
      "Epoch 26/100\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.3077 - accuracy: 0.8812\n",
      "Epoch 27/100\n",
      "202/202 [==============================] - 0s 275us/sample - loss: 0.3051 - accuracy: 0.8861\n",
      "Epoch 28/100\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.3023 - accuracy: 0.8861\n",
      "Epoch 29/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.2998 - accuracy: 0.8861\n",
      "Epoch 30/100\n",
      "202/202 [==============================] - 0s 258us/sample - loss: 0.2971 - accuracy: 0.8861\n",
      "Epoch 31/100\n",
      "202/202 [==============================] - 0s 251us/sample - loss: 0.2942 - accuracy: 0.8861\n",
      "Epoch 32/100\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.2914 - accuracy: 0.8960\n",
      "Epoch 33/100\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.2889 - accuracy: 0.8960\n",
      "Epoch 34/100\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.2868 - accuracy: 0.8960\n",
      "Epoch 35/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.2846 - accuracy: 0.8960\n",
      "Epoch 36/100\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.2815 - accuracy: 0.8960\n",
      "Epoch 37/100\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.2797 - accuracy: 0.9010\n",
      "Epoch 38/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.2774 - accuracy: 0.9059\n",
      "Epoch 39/100\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.2744 - accuracy: 0.9010\n",
      "Epoch 40/100\n",
      "202/202 [==============================] - 0s 254us/sample - loss: 0.2722 - accuracy: 0.9059\n",
      "Epoch 41/100\n",
      "202/202 [==============================] - 0s 288us/sample - loss: 0.2698 - accuracy: 0.8960\n",
      "Epoch 42/100\n",
      "202/202 [==============================] - 0s 278us/sample - loss: 0.2673 - accuracy: 0.9010\n",
      "Epoch 43/100\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.2648 - accuracy: 0.9059\n",
      "Epoch 44/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.2633 - accuracy: 0.9059\n",
      "Epoch 45/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.2609 - accuracy: 0.9059\n",
      "Epoch 46/100\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.2599 - accuracy: 0.9158\n",
      "Epoch 47/100\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.2572 - accuracy: 0.9158\n",
      "Epoch 48/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.2548 - accuracy: 0.9158\n",
      "Epoch 49/100\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.2525 - accuracy: 0.9158\n",
      "Epoch 50/100\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.2507 - accuracy: 0.9109\n",
      "Epoch 51/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.2489 - accuracy: 0.9158\n",
      "Epoch 52/100\n",
      "202/202 [==============================] - 0s 275us/sample - loss: 0.2472 - accuracy: 0.9158\n",
      "Epoch 53/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.2458 - accuracy: 0.9158\n",
      "Epoch 54/100\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.2444 - accuracy: 0.9208\n",
      "Epoch 55/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.2421 - accuracy: 0.9158\n",
      "Epoch 56/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.2402 - accuracy: 0.9158\n",
      "Epoch 57/100\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.2382 - accuracy: 0.9158\n",
      "Epoch 58/100\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.2359 - accuracy: 0.9158\n",
      "Epoch 59/100\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.2346 - accuracy: 0.9158\n",
      "Epoch 60/100\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.2326 - accuracy: 0.9158\n",
      "Epoch 61/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.2308 - accuracy: 0.9158\n",
      "Epoch 62/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.2302 - accuracy: 0.9158\n",
      "Epoch 63/100\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.2273 - accuracy: 0.9158\n",
      "Epoch 64/100\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.2257 - accuracy: 0.9158\n",
      "Epoch 65/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.2237 - accuracy: 0.9158\n",
      "Epoch 66/100\n",
      "202/202 [==============================] - 0s 309us/sample - loss: 0.2221 - accuracy: 0.9158\n",
      "Epoch 67/100\n",
      "202/202 [==============================] - 0s 308us/sample - loss: 0.2201 - accuracy: 0.9158\n",
      "Epoch 68/100\n",
      "202/202 [==============================] - 0s 299us/sample - loss: 0.2181 - accuracy: 0.9158\n",
      "Epoch 69/100\n",
      "202/202 [==============================] - 0s 285us/sample - loss: 0.2170 - accuracy: 0.9158\n",
      "Epoch 70/100\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.2153 - accuracy: 0.9208\n",
      "Epoch 71/100\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.2132 - accuracy: 0.9208\n",
      "Epoch 72/100\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.2114 - accuracy: 0.9257\n",
      "Epoch 73/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.2108 - accuracy: 0.9158\n",
      "Epoch 74/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.2085 - accuracy: 0.9208\n",
      "Epoch 75/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.2082 - accuracy: 0.9208\n",
      "Epoch 76/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.2053 - accuracy: 0.9257\n",
      "Epoch 77/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.2044 - accuracy: 0.9257\n",
      "Epoch 78/100\n",
      "202/202 [==============================] - 0s 317us/sample - loss: 0.2029 - accuracy: 0.9257\n",
      "Epoch 79/100\n",
      "202/202 [==============================] - 0s 304us/sample - loss: 0.2011 - accuracy: 0.9307\n",
      "Epoch 80/100\n",
      "202/202 [==============================] - 0s 289us/sample - loss: 0.1990 - accuracy: 0.9307\n",
      "Epoch 81/100\n",
      "202/202 [==============================] - 0s 356us/sample - loss: 0.1969 - accuracy: 0.9356\n",
      "Epoch 82/100\n",
      "202/202 [==============================] - 0s 274us/sample - loss: 0.1953 - accuracy: 0.9406\n",
      "Epoch 83/100\n",
      "202/202 [==============================] - 0s 269us/sample - loss: 0.1935 - accuracy: 0.9406\n",
      "Epoch 84/100\n",
      "202/202 [==============================] - 0s 275us/sample - loss: 0.1919 - accuracy: 0.9406\n",
      "Epoch 85/100\n",
      "202/202 [==============================] - 0s 276us/sample - loss: 0.1902 - accuracy: 0.9406\n",
      "Epoch 86/100\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.1891 - accuracy: 0.9406\n",
      "Epoch 87/100\n",
      "202/202 [==============================] - 0s 285us/sample - loss: 0.1869 - accuracy: 0.9455\n",
      "Epoch 88/100\n",
      "202/202 [==============================] - 0s 285us/sample - loss: 0.1859 - accuracy: 0.9455\n",
      "Epoch 89/100\n",
      "202/202 [==============================] - 0s 289us/sample - loss: 0.1849 - accuracy: 0.9455\n",
      "Epoch 90/100\n",
      "202/202 [==============================] - 0s 286us/sample - loss: 0.1839 - accuracy: 0.9455\n",
      "Epoch 91/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.1811 - accuracy: 0.9455\n",
      "Epoch 92/100\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.1807 - accuracy: 0.9455\n",
      "Epoch 93/100\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.1781 - accuracy: 0.9505\n",
      "Epoch 94/100\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.1772 - accuracy: 0.9505\n",
      "Epoch 95/100\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.1748 - accuracy: 0.9505\n",
      "Epoch 96/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.1732 - accuracy: 0.9505\n",
      "Epoch 97/100\n",
      "202/202 [==============================] - 0s 259us/sample - loss: 0.1727 - accuracy: 0.9455\n",
      "Epoch 98/100\n",
      "202/202 [==============================] - 0s 287us/sample - loss: 0.1696 - accuracy: 0.9505\n",
      "Epoch 99/100\n",
      "202/202 [==============================] - 0s 284us/sample - loss: 0.1679 - accuracy: 0.9505\n",
      "Epoch 100/100\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.1666 - accuracy: 0.9505\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.2355 - accuracy: 0.8416\n",
      "Train on 202 samples\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 1s 4ms/sample - loss: 0.7238 - accuracy: 0.5446\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 0s 291us/sample - loss: 0.6431 - accuracy: 0.6139\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 0s 312us/sample - loss: 0.5834 - accuracy: 0.6782\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.5379 - accuracy: 0.7426\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.5021 - accuracy: 0.7574\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 0s 291us/sample - loss: 0.4749 - accuracy: 0.7871\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 0s 278us/sample - loss: 0.4510 - accuracy: 0.8168\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 0s 287us/sample - loss: 0.4289 - accuracy: 0.8317\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 0s 285us/sample - loss: 0.4113 - accuracy: 0.8366\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 0s 282us/sample - loss: 0.3954 - accuracy: 0.8416\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.3829 - accuracy: 0.8465\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.3720 - accuracy: 0.8366\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.3629 - accuracy: 0.8366\n",
      "Epoch 14/100\n",
      "202/202 [==============================] - 0s 296us/sample - loss: 0.3555 - accuracy: 0.8515\n",
      "Epoch 15/100\n",
      "202/202 [==============================] - 0s 286us/sample - loss: 0.3483 - accuracy: 0.8564\n",
      "Epoch 16/100\n",
      "202/202 [==============================] - 0s 287us/sample - loss: 0.3417 - accuracy: 0.8564\n",
      "Epoch 17/100\n",
      "202/202 [==============================] - 0s 296us/sample - loss: 0.3358 - accuracy: 0.8614\n",
      "Epoch 18/100\n",
      "202/202 [==============================] - 0s 276us/sample - loss: 0.3316 - accuracy: 0.8614\n",
      "Epoch 19/100\n",
      "202/202 [==============================] - 0s 276us/sample - loss: 0.3263 - accuracy: 0.8713\n",
      "Epoch 20/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.3221 - accuracy: 0.8713\n",
      "Epoch 21/100\n",
      "202/202 [==============================] - 0s 275us/sample - loss: 0.3168 - accuracy: 0.8713\n",
      "Epoch 22/100\n",
      "202/202 [==============================] - 0s 283us/sample - loss: 0.3128 - accuracy: 0.8713\n",
      "Epoch 23/100\n",
      "202/202 [==============================] - 0s 288us/sample - loss: 0.3096 - accuracy: 0.8713\n",
      "Epoch 24/100\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.3059 - accuracy: 0.8762\n",
      "Epoch 25/100\n",
      "202/202 [==============================] - 0s 288us/sample - loss: 0.3018 - accuracy: 0.8713\n",
      "Epoch 26/100\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.2992 - accuracy: 0.8713\n",
      "Epoch 27/100\n",
      "202/202 [==============================] - 0s 286us/sample - loss: 0.2963 - accuracy: 0.8663\n",
      "Epoch 28/100\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.2920 - accuracy: 0.8713\n",
      "Epoch 29/100\n",
      "202/202 [==============================] - 0s 279us/sample - loss: 0.2900 - accuracy: 0.8713\n",
      "Epoch 30/100\n",
      "202/202 [==============================] - 0s 289us/sample - loss: 0.2874 - accuracy: 0.8713\n",
      "Epoch 31/100\n",
      "202/202 [==============================] - 0s 280us/sample - loss: 0.2850 - accuracy: 0.8812\n",
      "Epoch 32/100\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.2816 - accuracy: 0.8812\n",
      "Epoch 33/100\n",
      "202/202 [==============================] - 0s 276us/sample - loss: 0.2795 - accuracy: 0.8812\n",
      "Epoch 34/100\n",
      "202/202 [==============================] - 0s 315us/sample - loss: 0.2767 - accuracy: 0.8911\n",
      "Epoch 35/100\n",
      "202/202 [==============================] - 0s 287us/sample - loss: 0.2748 - accuracy: 0.8960\n",
      "Epoch 36/100\n",
      "202/202 [==============================] - 0s 278us/sample - loss: 0.2728 - accuracy: 0.9010\n",
      "Epoch 37/100\n",
      "202/202 [==============================] - 0s 287us/sample - loss: 0.2706 - accuracy: 0.8960\n",
      "Epoch 38/100\n",
      "202/202 [==============================] - 0s 293us/sample - loss: 0.2686 - accuracy: 0.9010\n",
      "Epoch 39/100\n",
      "202/202 [==============================] - 0s 335us/sample - loss: 0.2660 - accuracy: 0.8960\n",
      "Epoch 40/100\n",
      "202/202 [==============================] - 0s 300us/sample - loss: 0.2645 - accuracy: 0.9010\n",
      "Epoch 41/100\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.2622 - accuracy: 0.8960\n",
      "Epoch 42/100\n",
      "202/202 [==============================] - 0s 304us/sample - loss: 0.2610 - accuracy: 0.9010\n",
      "Epoch 43/100\n",
      "202/202 [==============================] - 0s 294us/sample - loss: 0.2586 - accuracy: 0.8960\n",
      "Epoch 44/100\n",
      "202/202 [==============================] - 0s 285us/sample - loss: 0.2568 - accuracy: 0.9010\n",
      "Epoch 45/100\n",
      "202/202 [==============================] - 0s 285us/sample - loss: 0.2556 - accuracy: 0.9059\n",
      "Epoch 46/100\n",
      "202/202 [==============================] - 0s 291us/sample - loss: 0.2520 - accuracy: 0.9010\n",
      "Epoch 47/100\n",
      "202/202 [==============================] - 0s 284us/sample - loss: 0.2505 - accuracy: 0.9059\n",
      "Epoch 48/100\n",
      "202/202 [==============================] - 0s 276us/sample - loss: 0.2479 - accuracy: 0.9059\n",
      "Epoch 49/100\n",
      "202/202 [==============================] - 0s 278us/sample - loss: 0.2469 - accuracy: 0.9010\n",
      "Epoch 50/100\n",
      "202/202 [==============================] - 0s 334us/sample - loss: 0.2453 - accuracy: 0.9059\n",
      "Epoch 51/100\n",
      "202/202 [==============================] - 0s 331us/sample - loss: 0.2438 - accuracy: 0.9109\n",
      "Epoch 52/100\n",
      "202/202 [==============================] - 0s 289us/sample - loss: 0.2417 - accuracy: 0.9109\n",
      "Epoch 53/100\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.2413 - accuracy: 0.9109\n",
      "Epoch 54/100\n",
      "202/202 [==============================] - 0s 276us/sample - loss: 0.2368 - accuracy: 0.9109\n",
      "Epoch 55/100\n",
      "202/202 [==============================] - 0s 269us/sample - loss: 0.2378 - accuracy: 0.9109\n",
      "Epoch 56/100\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.2357 - accuracy: 0.9109\n",
      "Epoch 57/100\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.2344 - accuracy: 0.9059\n",
      "Epoch 58/100\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.2311 - accuracy: 0.9109\n",
      "Epoch 59/100\n",
      "202/202 [==============================] - 0s 306us/sample - loss: 0.2299 - accuracy: 0.9109\n",
      "Epoch 60/100\n",
      "202/202 [==============================] - 0s 290us/sample - loss: 0.2280 - accuracy: 0.9109\n",
      "Epoch 61/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.2270 - accuracy: 0.9109\n",
      "Epoch 62/100\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.2261 - accuracy: 0.9059\n",
      "Epoch 63/100\n",
      "202/202 [==============================] - 0s 289us/sample - loss: 0.2240 - accuracy: 0.9158\n",
      "Epoch 64/100\n",
      "202/202 [==============================] - 0s 294us/sample - loss: 0.2230 - accuracy: 0.9208\n",
      "Epoch 65/100\n",
      "202/202 [==============================] - 0s 289us/sample - loss: 0.2213 - accuracy: 0.9158\n",
      "Epoch 66/100\n",
      "202/202 [==============================] - 0s 274us/sample - loss: 0.2203 - accuracy: 0.9208\n",
      "Epoch 67/100\n",
      "202/202 [==============================] - 0s 291us/sample - loss: 0.2185 - accuracy: 0.9257\n",
      "Epoch 68/100\n",
      "202/202 [==============================] - 0s 294us/sample - loss: 0.2172 - accuracy: 0.9307\n",
      "Epoch 69/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.2158 - accuracy: 0.9307\n",
      "Epoch 70/100\n",
      "202/202 [==============================] - 0s 274us/sample - loss: 0.2141 - accuracy: 0.9257\n",
      "Epoch 71/100\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.2134 - accuracy: 0.9307\n",
      "Epoch 72/100\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.2111 - accuracy: 0.9307\n",
      "Epoch 73/100\n",
      "202/202 [==============================] - 0s 276us/sample - loss: 0.2099 - accuracy: 0.9307\n",
      "Epoch 74/100\n",
      "202/202 [==============================] - 0s 279us/sample - loss: 0.2079 - accuracy: 0.9307\n",
      "Epoch 75/100\n",
      "202/202 [==============================] - 0s 288us/sample - loss: 0.2076 - accuracy: 0.9257\n",
      "Epoch 76/100\n",
      "202/202 [==============================] - 0s 291us/sample - loss: 0.2047 - accuracy: 0.9307\n",
      "Epoch 77/100\n",
      "202/202 [==============================] - 0s 291us/sample - loss: 0.2034 - accuracy: 0.9257\n",
      "Epoch 78/100\n",
      "202/202 [==============================] - 0s 284us/sample - loss: 0.2017 - accuracy: 0.9307\n",
      "Epoch 79/100\n",
      "202/202 [==============================] - 0s 294us/sample - loss: 0.2019 - accuracy: 0.9307\n",
      "Epoch 80/100\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.2004 - accuracy: 0.9257\n",
      "Epoch 81/100\n",
      "202/202 [==============================] - 0s 284us/sample - loss: 0.1995 - accuracy: 0.9257\n",
      "Epoch 82/100\n",
      "202/202 [==============================] - 0s 287us/sample - loss: 0.1973 - accuracy: 0.9307\n",
      "Epoch 83/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.1964 - accuracy: 0.9257\n",
      "Epoch 84/100\n",
      "202/202 [==============================] - 0s 285us/sample - loss: 0.1940 - accuracy: 0.9307\n",
      "Epoch 85/100\n",
      "202/202 [==============================] - 0s 296us/sample - loss: 0.1925 - accuracy: 0.9307\n",
      "Epoch 86/100\n",
      "202/202 [==============================] - 0s 278us/sample - loss: 0.1919 - accuracy: 0.9307\n",
      "Epoch 87/100\n",
      "202/202 [==============================] - 0s 288us/sample - loss: 0.1901 - accuracy: 0.9307\n",
      "Epoch 88/100\n",
      "202/202 [==============================] - 0s 274us/sample - loss: 0.1885 - accuracy: 0.9307\n",
      "Epoch 89/100\n",
      "202/202 [==============================] - 0s 274us/sample - loss: 0.1887 - accuracy: 0.9356\n",
      "Epoch 90/100\n",
      "202/202 [==============================] - 0s 284us/sample - loss: 0.1866 - accuracy: 0.9307\n",
      "Epoch 91/100\n",
      "202/202 [==============================] - 0s 299us/sample - loss: 0.1843 - accuracy: 0.9406\n",
      "Epoch 92/100\n",
      "202/202 [==============================] - 0s 289us/sample - loss: 0.1829 - accuracy: 0.9455\n",
      "Epoch 93/100\n",
      "202/202 [==============================] - 0s 299us/sample - loss: 0.1826 - accuracy: 0.9406\n",
      "Epoch 94/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.1810 - accuracy: 0.9356\n",
      "Epoch 95/100\n",
      "202/202 [==============================] - 0s 293us/sample - loss: 0.1795 - accuracy: 0.9356\n",
      "Epoch 96/100\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.1786 - accuracy: 0.9455\n",
      "Epoch 97/100\n",
      "202/202 [==============================] - 0s 278us/sample - loss: 0.1779 - accuracy: 0.9406\n",
      "Epoch 98/100\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.1755 - accuracy: 0.9505\n",
      "Epoch 99/100\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.1742 - accuracy: 0.9505\n",
      "Epoch 100/100\n",
      "202/202 [==============================] - 0s 288us/sample - loss: 0.1737 - accuracy: 0.9455\n",
      "101/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 0.2616 - accuracy: 0.8218\n",
      "Train on 303 samples\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 0s 2ms/sample - loss: 0.6024 - accuracy: 0.7063\n",
      "Epoch 2/100\n",
      "303/303 [==============================] - 0s 266us/sample - loss: 0.5732 - accuracy: 0.7492\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 0s 262us/sample - loss: 0.5482 - accuracy: 0.7591\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 0s 254us/sample - loss: 0.5241 - accuracy: 0.7888\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 0s 274us/sample - loss: 0.4999 - accuracy: 0.7954\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 0s 282us/sample - loss: 0.4754 - accuracy: 0.8020\n",
      "Epoch 7/100\n",
      "303/303 [==============================] - 0s 288us/sample - loss: 0.4526 - accuracy: 0.8086\n",
      "Epoch 8/100\n",
      "303/303 [==============================] - 0s 268us/sample - loss: 0.4308 - accuracy: 0.8185\n",
      "Epoch 9/100\n",
      "303/303 [==============================] - 0s 268us/sample - loss: 0.4115 - accuracy: 0.8218\n",
      "Epoch 10/100\n",
      "303/303 [==============================] - 0s 269us/sample - loss: 0.3944 - accuracy: 0.8284\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 0s 267us/sample - loss: 0.3793 - accuracy: 0.8383\n",
      "Epoch 12/100\n",
      "303/303 [==============================] - 0s 342us/sample - loss: 0.3667 - accuracy: 0.8482\n",
      "Epoch 13/100\n",
      "303/303 [==============================] - 0s 289us/sample - loss: 0.3567 - accuracy: 0.8548\n",
      "Epoch 14/100\n",
      "303/303 [==============================] - 0s 264us/sample - loss: 0.3481 - accuracy: 0.8548\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 0s 264us/sample - loss: 0.3419 - accuracy: 0.8548\n",
      "Epoch 16/100\n",
      "303/303 [==============================] - 0s 261us/sample - loss: 0.3356 - accuracy: 0.8548\n",
      "Epoch 17/100\n",
      "303/303 [==============================] - 0s 278us/sample - loss: 0.3313 - accuracy: 0.8548\n",
      "Epoch 18/100\n",
      "303/303 [==============================] - 0s 350us/sample - loss: 0.3260 - accuracy: 0.8548\n",
      "Epoch 19/100\n",
      "303/303 [==============================] - 0s 289us/sample - loss: 0.3228 - accuracy: 0.8614\n",
      "Epoch 20/100\n",
      "303/303 [==============================] - 0s 267us/sample - loss: 0.3181 - accuracy: 0.8614\n",
      "Epoch 21/100\n",
      "303/303 [==============================] - 0s 259us/sample - loss: 0.3150 - accuracy: 0.8647\n",
      "Epoch 22/100\n",
      "303/303 [==============================] - 0s 266us/sample - loss: 0.3125 - accuracy: 0.8647\n",
      "Epoch 23/100\n",
      "303/303 [==============================] - 0s 271us/sample - loss: 0.3088 - accuracy: 0.8647\n",
      "Epoch 24/100\n",
      "303/303 [==============================] - 0s 255us/sample - loss: 0.3069 - accuracy: 0.8680\n",
      "Epoch 25/100\n",
      "303/303 [==============================] - 0s 264us/sample - loss: 0.3054 - accuracy: 0.8713\n",
      "Epoch 26/100\n",
      "303/303 [==============================] - 0s 263us/sample - loss: 0.3020 - accuracy: 0.8713\n",
      "Epoch 27/100\n",
      "303/303 [==============================] - 0s 261us/sample - loss: 0.2980 - accuracy: 0.8713\n",
      "Epoch 28/100\n",
      "303/303 [==============================] - 0s 270us/sample - loss: 0.2963 - accuracy: 0.8713\n",
      "Epoch 29/100\n",
      "303/303 [==============================] - 0s 260us/sample - loss: 0.2941 - accuracy: 0.8713\n",
      "Epoch 30/100\n",
      "303/303 [==============================] - 0s 269us/sample - loss: 0.2921 - accuracy: 0.8746\n",
      "Epoch 31/100\n",
      "303/303 [==============================] - 0s 268us/sample - loss: 0.2902 - accuracy: 0.8746\n",
      "Epoch 32/100\n",
      "303/303 [==============================] - 0s 267us/sample - loss: 0.2885 - accuracy: 0.8746\n",
      "Epoch 33/100\n",
      "303/303 [==============================] - 0s 275us/sample - loss: 0.2857 - accuracy: 0.8746\n",
      "Epoch 34/100\n",
      "303/303 [==============================] - 0s 265us/sample - loss: 0.2834 - accuracy: 0.8746\n",
      "Epoch 35/100\n",
      "303/303 [==============================] - 0s 272us/sample - loss: 0.2813 - accuracy: 0.8746\n",
      "Epoch 36/100\n",
      "303/303 [==============================] - 0s 278us/sample - loss: 0.2788 - accuracy: 0.8812\n",
      "Epoch 37/100\n",
      "303/303 [==============================] - 0s 274us/sample - loss: 0.2764 - accuracy: 0.8845\n",
      "Epoch 38/100\n",
      "303/303 [==============================] - 0s 260us/sample - loss: 0.2744 - accuracy: 0.8878\n",
      "Epoch 39/100\n",
      "303/303 [==============================] - 0s 261us/sample - loss: 0.2723 - accuracy: 0.8878\n",
      "Epoch 40/100\n",
      "303/303 [==============================] - 0s 264us/sample - loss: 0.2710 - accuracy: 0.8878\n",
      "Epoch 41/100\n",
      "303/303 [==============================] - 0s 277us/sample - loss: 0.2694 - accuracy: 0.8944\n",
      "Epoch 42/100\n",
      "303/303 [==============================] - 0s 277us/sample - loss: 0.2672 - accuracy: 0.8911\n",
      "Epoch 43/100\n",
      "303/303 [==============================] - 0s 260us/sample - loss: 0.2646 - accuracy: 0.8944\n",
      "Epoch 44/100\n",
      "303/303 [==============================] - 0s 270us/sample - loss: 0.2624 - accuracy: 0.8944\n",
      "Epoch 45/100\n",
      "303/303 [==============================] - 0s 280us/sample - loss: 0.2609 - accuracy: 0.8944\n",
      "Epoch 46/100\n",
      "303/303 [==============================] - 0s 267us/sample - loss: 0.2591 - accuracy: 0.8977\n",
      "Epoch 47/100\n",
      "303/303 [==============================] - 0s 280us/sample - loss: 0.2573 - accuracy: 0.8977\n",
      "Epoch 48/100\n",
      "303/303 [==============================] - 0s 267us/sample - loss: 0.2549 - accuracy: 0.9010\n",
      "Epoch 49/100\n",
      "303/303 [==============================] - 0s 277us/sample - loss: 0.2542 - accuracy: 0.9043\n",
      "Epoch 50/100\n",
      "303/303 [==============================] - 0s 275us/sample - loss: 0.2519 - accuracy: 0.9076\n",
      "Epoch 51/100\n",
      "303/303 [==============================] - 0s 265us/sample - loss: 0.2507 - accuracy: 0.9076\n",
      "Epoch 52/100\n",
      "303/303 [==============================] - 0s 266us/sample - loss: 0.2491 - accuracy: 0.9109\n",
      "Epoch 53/100\n",
      "303/303 [==============================] - 0s 274us/sample - loss: 0.2482 - accuracy: 0.9076\n",
      "Epoch 54/100\n",
      "303/303 [==============================] - 0s 269us/sample - loss: 0.2452 - accuracy: 0.9076\n",
      "Epoch 55/100\n",
      "303/303 [==============================] - 0s 276us/sample - loss: 0.2435 - accuracy: 0.9142\n",
      "Epoch 56/100\n",
      "303/303 [==============================] - 0s 267us/sample - loss: 0.2419 - accuracy: 0.9109\n",
      "Epoch 57/100\n",
      "303/303 [==============================] - 0s 266us/sample - loss: 0.2405 - accuracy: 0.9109\n",
      "Epoch 58/100\n",
      "303/303 [==============================] - 0s 268us/sample - loss: 0.2386 - accuracy: 0.9142\n",
      "Epoch 59/100\n",
      "303/303 [==============================] - 0s 275us/sample - loss: 0.2374 - accuracy: 0.9109\n",
      "Epoch 60/100\n",
      "303/303 [==============================] - 0s 274us/sample - loss: 0.2361 - accuracy: 0.9142\n",
      "Epoch 61/100\n",
      "303/303 [==============================] - 0s 264us/sample - loss: 0.2340 - accuracy: 0.9142\n",
      "Epoch 62/100\n",
      "303/303 [==============================] - 0s 262us/sample - loss: 0.2320 - accuracy: 0.9175\n",
      "Epoch 63/100\n",
      "303/303 [==============================] - 0s 264us/sample - loss: 0.2325 - accuracy: 0.9142\n",
      "Epoch 64/100\n",
      "303/303 [==============================] - 0s 256us/sample - loss: 0.2304 - accuracy: 0.9109\n",
      "Epoch 65/100\n",
      "303/303 [==============================] - 0s 265us/sample - loss: 0.2281 - accuracy: 0.9175\n",
      "Epoch 66/100\n",
      "303/303 [==============================] - 0s 267us/sample - loss: 0.2255 - accuracy: 0.9241\n",
      "Epoch 67/100\n",
      "303/303 [==============================] - 0s 278us/sample - loss: 0.2231 - accuracy: 0.9175\n",
      "Epoch 68/100\n",
      "303/303 [==============================] - 0s 271us/sample - loss: 0.2239 - accuracy: 0.9142\n",
      "Epoch 69/100\n",
      "303/303 [==============================] - 0s 258us/sample - loss: 0.2205 - accuracy: 0.9208\n",
      "Epoch 70/100\n",
      "303/303 [==============================] - 0s 263us/sample - loss: 0.2190 - accuracy: 0.9274\n",
      "Epoch 71/100\n",
      "303/303 [==============================] - 0s 267us/sample - loss: 0.2181 - accuracy: 0.9208\n",
      "Epoch 72/100\n",
      "303/303 [==============================] - 0s 267us/sample - loss: 0.2154 - accuracy: 0.9274\n",
      "Epoch 73/100\n",
      "303/303 [==============================] - 0s 266us/sample - loss: 0.2145 - accuracy: 0.9274\n",
      "Epoch 74/100\n",
      "303/303 [==============================] - 0s 297us/sample - loss: 0.2124 - accuracy: 0.9241\n",
      "Epoch 75/100\n",
      "303/303 [==============================] - 0s 285us/sample - loss: 0.2111 - accuracy: 0.9241\n",
      "Epoch 76/100\n",
      "303/303 [==============================] - 0s 270us/sample - loss: 0.2113 - accuracy: 0.9241\n",
      "Epoch 77/100\n",
      "303/303 [==============================] - 0s 263us/sample - loss: 0.2080 - accuracy: 0.9241\n",
      "Epoch 78/100\n",
      "303/303 [==============================] - 0s 258us/sample - loss: 0.2074 - accuracy: 0.9274\n",
      "Epoch 79/100\n",
      "303/303 [==============================] - 0s 263us/sample - loss: 0.2042 - accuracy: 0.9274\n",
      "Epoch 80/100\n",
      "303/303 [==============================] - 0s 266us/sample - loss: 0.2028 - accuracy: 0.9241\n",
      "Epoch 81/100\n",
      "303/303 [==============================] - 0s 292us/sample - loss: 0.2015 - accuracy: 0.9241\n",
      "Epoch 82/100\n",
      "303/303 [==============================] - 0s 322us/sample - loss: 0.1994 - accuracy: 0.9274\n",
      "Epoch 83/100\n",
      "303/303 [==============================] - 0s 290us/sample - loss: 0.1978 - accuracy: 0.9274\n",
      "Epoch 84/100\n",
      "303/303 [==============================] - 0s 285us/sample - loss: 0.1964 - accuracy: 0.9307\n",
      "Epoch 85/100\n",
      "303/303 [==============================] - 0s 263us/sample - loss: 0.1953 - accuracy: 0.9274\n",
      "Epoch 86/100\n",
      "303/303 [==============================] - 0s 269us/sample - loss: 0.1929 - accuracy: 0.9274\n",
      "Epoch 87/100\n",
      "303/303 [==============================] - 0s 263us/sample - loss: 0.1916 - accuracy: 0.9307\n",
      "Epoch 88/100\n",
      "303/303 [==============================] - 0s 263us/sample - loss: 0.1915 - accuracy: 0.9340\n",
      "Epoch 89/100\n",
      "303/303 [==============================] - 0s 269us/sample - loss: 0.1890 - accuracy: 0.9274\n",
      "Epoch 90/100\n",
      "303/303 [==============================] - 0s 266us/sample - loss: 0.1878 - accuracy: 0.9340\n",
      "Epoch 91/100\n",
      "303/303 [==============================] - 0s 260us/sample - loss: 0.1851 - accuracy: 0.9373\n",
      "Epoch 92/100\n",
      "303/303 [==============================] - 0s 258us/sample - loss: 0.1846 - accuracy: 0.9373\n",
      "Epoch 93/100\n",
      "303/303 [==============================] - 0s 255us/sample - loss: 0.1834 - accuracy: 0.9373\n",
      "Epoch 94/100\n",
      "303/303 [==============================] - 0s 260us/sample - loss: 0.1815 - accuracy: 0.9406\n",
      "Epoch 95/100\n",
      "303/303 [==============================] - 0s 275us/sample - loss: 0.1791 - accuracy: 0.9406\n",
      "Epoch 96/100\n",
      "303/303 [==============================] - 0s 279us/sample - loss: 0.1768 - accuracy: 0.9439\n",
      "Epoch 97/100\n",
      "303/303 [==============================] - 0s 273us/sample - loss: 0.1758 - accuracy: 0.9439\n",
      "Epoch 98/100\n",
      "303/303 [==============================] - 0s 272us/sample - loss: 0.1746 - accuracy: 0.9439\n",
      "Epoch 99/100\n",
      "303/303 [==============================] - 0s 267us/sample - loss: 0.1737 - accuracy: 0.9406\n",
      "Epoch 100/100\n",
      "303/303 [==============================] - 0s 258us/sample - loss: 0.1724 - accuracy: 0.9439\n"
     ]
    }
   ],
   "source": [
    "# create model f(x) for keras sklearn wrapper\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(13, activation='relu', input_shape=(X.shape[1],)))\n",
    "    model.add(Dense(6, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=True)\n",
    "\n",
    "# now keep best batch size and explor epochs\n",
    "param_grid = {\n",
    "    'batch_size': [10],\n",
    "    'epochs': [10, 20, 50, 100]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_results = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'batch_size': 10, 'epochs': 100}\n",
      "Best Score with these Params: 0.8349834879239401\n"
     ]
    }
   ],
   "source": [
    "# Epochs had a bigger impact than batch size - took it up to 81.5%\n",
    "print(\"Best Params:\", grid_results.best_params_)\n",
    "print(\"Best Score with these Params:\", grid_results.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
